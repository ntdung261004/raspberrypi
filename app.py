import sys
import cv2
import numpy as np
from datetime import datetime
from threading import Thread
import queue
import time
import base64
import requests

from module.detection_module import ObjectDetector
from utils.audio import play_event_sound, play_score_sound 
from utils.processing import check_object_center, warp_crop_to_original, calculate_score

# Thay th·∫ø b·∫±ng ƒë·ªãa ch·ªâ IP ch√≠nh x√°c c·ªßa m√°y Mac c·ªßa b·∫°n
SERVER_MAC_URL = "http://192.168.1.196:5000"

ORIGINAL_IMAGE_PATH = "images/original/bia_so_4.jpg"
DEFAULT_MASK_PATH = "images/mask/mask_bia_so_4.jpg"

class ProcessingWorker(Thread):
    def __init__(self, process_queue, detector):
        super().__init__()
        self.process_queue = process_queue
        self.detector = detector
        self.original_img = cv2.imread(ORIGINAL_IMAGE_PATH)
        self.mask = cv2.imread(DEFAULT_MASK_PATH, cv2.IMREAD_GRAYSCALE)
        self.daemon = True
        self.running = True
        print("üí° ProcessingWorker ƒë√£ kh·ªüi ƒë·ªông.")
    
    def run(self):
        while self.running:
            try:
                # <<< S·ª¨A ƒê·ªîI: Nh·∫≠n th√™m 'center_coords' t·ª´ h√†ng ƒë·ª£i >>>
                frame, capture_time, center_coords = self.process_queue.get(timeout=0.1)
                self._process_frame(frame, capture_time, center_coords)
                self.process_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"L·ªói trong lu·ªìng x·ª≠ l√Ω: {e}")
    
    # <<< S·ª¨A ƒê·ªîI: Th√™m 'center_coords' v√†o h√†m _process_frame >>>
    def _process_frame(self, frame, capture_time, center_coords):
        print(f"‚úÖ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω ·∫£nh ch·ª•p l√∫c {capture_time}...")
        
        # <<< S·ª¨A ƒê·ªîI: Truy·ªÅn t√¢m ng·∫Øm v√†o h√†m check_object_center >>>
        results = self.detector.detect(frame, conf=0.5)
        status, obj_crop, shot_point = check_object_center(results, frame, center_coords, conf_threshold=0.5)
        
        result_data = {
            'time': capture_time,
            'target': 'Bia s·ªë 4',
            'score': '--',
            'image_data': ''
        }
        
        processed_image = frame.copy()
        score = 0
        
        if status == "TR√öNG" and obj_crop is not None:
            warped_img, transformed_point = warp_crop_to_original(self.original_img, obj_crop, shot_point)
            
            if warped_img is not None and transformed_point is not None:
                print("ƒê√£ warp th√†nh c√¥ng. ƒêang t√≠nh ƒëi·ªÉm.")
                score = calculate_score(transformed_point, self.original_img, self.mask)
                cv2.drawMarker(warped_img, (int(transformed_point[0]), int(transformed_point[1])), 
                               (0, 0, 255), cv2.MARKER_CROSS, markerSize=20, thickness=2)
                processed_image = warped_img
            else:
                print("‚ùå Warp th·∫•t b·∫°i. ƒêang t√≠nh ƒëi·ªÉm tr√™n ·∫£nh crop.")
                h_orig, w_orig = self.original_img.shape[:2]
                h_crop, w_crop = obj_crop.shape[:2]
                resized_obj_crop = cv2.resize(obj_crop, (w_orig, h_orig))
                scaled_shot_point_x = int(shot_point[0] * w_orig / w_crop)
                scaled_shot_point_y = int(shot_point[1] * h_orig / h_crop)
                scaled_shot_point = (scaled_shot_point_x, scaled_shot_point_y)
                score = calculate_score(scaled_shot_point, self.original_img, self.mask)
                cv2.drawMarker(resized_obj_crop, scaled_shot_point, 
                               (0, 0, 255), cv2.MARKER_CROSS, markerSize=20, thickness=2)
                processed_image = resized_obj_crop
            
            result_data.update({"score": score})
            play_score_sound(score)
            
        elif status == "TR∆Ø·ª¢T":
            print("‚ùå B·∫Øn kh√¥ng tr√∫ng m·ª•c ti√™u.")
            result_data.update({
                "score": 0,
                "target": "Kh√¥ng tr√∫ng m·ª•c ti√™u"
            })
            # Gi·ªØ l·∫°i logic v·∫Ω marker c≈© c·ªßa b·∫°n cho tr∆∞·ªùng h·ª£p n√†y
            processed_image = cv2.resize(frame, (500, 500))
            center = (processed_image.shape[1] // 2, processed_image.shape[0] // 2)
            cv2.drawMarker(processed_image, center, 
                           (0, 0, 255), cv2.MARKER_CROSS, markerSize=20, thickness=2)
            play_score_sound(0)
            
        else: # Bao g·ªìm c·∫£ tr∆∞·ªùng h·ª£p "KH√îNG_PH√ÅT_HI·ªÜN"
            print("‚ö† Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c k·∫øt qu·∫£.")
            result_data.update({
                "score": 0,
                "target": "Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c"
            })
            processed_image = cv2.resize(frame, (500, 500))
            center = (processed_image.shape[1] // 2, processed_image.shape[0] // 2)
            cv2.drawMarker(processed_image, center, 
                           (0, 0, 255), cv2.MARKER_CROSS, markerSize=20, thickness=2)
            play_score_sound(0)
        
        _, img_buffer = cv2.imencode('.jpg', processed_image)
        result_data['image_data'] = base64.b64encode(img_buffer).decode('utf-8')
        
        try:
            requests.post(f"{SERVER_MAC_URL}/processed_data_upload", json=result_data, timeout=5)
            print("üöÄ ƒê√£ g·ª≠i d·ªØ li·ªáu x·ª≠ l√Ω l√™n server th√†nh c√¥ng.")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå L·ªói khi g·ª≠i d·ªØ li·ªáu x·ª≠ l√Ω: {e}")

    def stop(self):
        self.running = False
        print("üõë ProcessingWorker ƒë√£ d·ª´ng.")