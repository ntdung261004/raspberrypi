import sys
import cv2
import numpy as np
from datetime import datetime
from threading import Thread
import queue
import time
from typing import Optional, Tuple, List
import base64
import requests
from flask import Flask, jsonify

from module.camera_module import Camera
from module.detection_module import ObjectDetector
from utils.audio import play_event_sound, play_score_sound 
from utils.processing import check_object_center, warp_crop_to_original, calculate_score

# Thay th·∫ø b·∫±ng ƒë·ªãa ch·ªâ IP ch√≠nh x√°c c·ªßa m√°y Mac c·ªßa b·∫°n
SERVER_MAC_URL = "http://192.168.1.134:5000"

ORIGINAL_IMAGE_PATH = "images/original/bia_so_4.jpg"
DEFAULT_MASK_PATH = "images/mask/mask_bia_so_4.jpg"

app = Flask(__name__)

class ProcessingWorker(Thread):
    def __init__(self, process_queue, detector):
        super().__init__()
        self.process_queue = process_queue
        self.detector = detector
        self.original_img = cv2.imread(ORIGINAL_IMAGE_PATH)
        self.mask = cv2.imread(DEFAULT_MASK_PATH, cv2.IMREAD_GRAYSCALE)
        self.daemon = True
        self.running = True
        print("üí° ProcessingWorker ƒë√£ kh·ªüi ƒë·ªông.")
    
    def run(self):
        while self.running:
            try:
                frame, capture_time, center_coords = self.process_queue.get(timeout=0.1)
                self._process_frame(frame, capture_time, center_coords)
                self.process_queue.task_done()
            except queue.Empty:
                continue
            except Exception as e:
                print(f"L·ªói trong lu·ªìng x·ª≠ l√Ω: {e}")
    
    def _process_frame(self, frame, capture_time, center_coords):
        print(f"‚úÖ B·∫Øt ƒë·∫ßu x·ª≠ l√Ω ·∫£nh ch·ª•p l√∫c {capture_time}...")
        
        results = self.detector.detect(frame, conf=0.6)
        status, obj_crop, shot_point = check_object_center(results, frame, center_coords, conf_threshold=0.6)
        
        result_data = {
            'time': capture_time,
            'target': 'Bia s·ªë 4',
            'score': '--',
            'image_data': ''
        }
        
        processed_image = frame.copy()
        score = 0
        
        # <<< KH·ªêI L·ªÜNH ƒê√É ƒê∆Ø·ª¢C S·ª¨A ƒê·ªîI HO√ÄN TO√ÄN >>>
        if status == "TR√öNG" and obj_crop is not None:
            # Lu√¥n b·∫Øt ƒë·∫ßu v·ªõi ·∫£nh bia g·ªëc s·∫°ch s·∫Ω
            processed_image = self.original_img.copy()
            
            # C·ªë g·∫Øng warp ƒë·ªÉ t√¨m t·ªça ƒë·ªô ch√≠nh x√°c tr√™n bia g·ªëc
            warped_img, transformed_point = warp_crop_to_original(self.original_img, obj_crop, shot_point)
            
            if warped_img is not None and transformed_point is not None:
                print("ƒê√£ warp th√†nh c√¥ng. ƒêang t√≠nh ƒëi·ªÉm.")
                score = calculate_score(transformed_point, self.original_img, self.mask)
                # V·∫Ω ƒëi·ªÉm ch·∫°m ƒë√£ warp l√™n bia g·ªëc
                cv2.drawMarker(processed_image, (int(transformed_point[0]), int(transformed_point[1])), 
                               (0, 0, 255), cv2.MARKER_CROSS, markerSize=40, thickness=3)
            else:
                print("‚ùå Warp th·∫•t b·∫°i. ƒêang t√≠nh ƒëi·ªÉm tr√™n ·∫£nh crop.")
                # N·∫øu warp th·∫•t b·∫°i, t√≠nh ƒëi·ªÉm d·ª±a tr√™n vi·ªác co gi√£n ·∫£nh crop
                h_orig, w_orig = self.original_img.shape[:2]
                h_crop, w_crop = obj_crop.shape[:2]
                
                scaled_shot_point_x = int(shot_point[0] * w_orig / w_crop)
                scaled_shot_point_y = int(shot_point[1] * h_orig / h_crop)
                scaled_shot_point = (scaled_shot_point_x, scaled_shot_point_y)
                
                score = calculate_score(scaled_shot_point, self.original_img, self.mask)
                # V·∫Ω ƒëi·ªÉm ch·∫°m ƒë√£ co gi√£n l√™n bia g·ªëc
                cv2.drawMarker(processed_image, scaled_shot_point, 
                               (0, 0, 255), cv2.MARKER_CROSS, markerSize=40, thickness=3)
            
            result_data.update({"score": score})
            play_score_sound(score)
            
        elif status == "TR∆Ø·ª¢T":
            print("‚ùå B·∫Øn kh√¥ng tr√∫ng m·ª•c ti√™u.")
            result_data.update({"score": 0, "target": "Kh√¥ng tr√∫ng m·ª•c ti√™u"})
            processed_image = frame.copy() 
            cv2.drawMarker(processed_image, shot_point, 
                           (0, 0, 255), cv2.MARKER_CROSS, markerSize=30, thickness=2)
            play_score_sound(0)
            
        else: # Bao g·ªìm c·∫£ tr∆∞·ªùng h·ª£p "KH√îNG_PH√ÅT_HI·ªÜN"
            print("‚ö† Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c k·∫øt qu·∫£.")
            result_data.update({"score": 0, "target": "Kh√¥ng x·ª≠ l√Ω ƒë∆∞·ª£c"})
            processed_image = frame.copy()
            cv2.drawMarker(processed_image, shot_point, 
                           (0, 0, 255), cv2.MARKER_CROSS, markerSize=30, thickness=2)
            play_score_sound(0)
        # <<< K·∫æT TH√öC S·ª¨A ƒê·ªîI >>>
        
        _, img_buffer = cv2.imencode('.jpg', processed_image)
        result_data['image_data'] = base64.b64encode(img_buffer).decode('utf-8')
        
        try:
            requests.post(f"{SERVER_MAC_URL}/processed_data_upload", json=result_data, timeout=5)
            print("üöÄ ƒê√£ g·ª≠i d·ªØ li·ªáu x·ª≠ l√Ω l√™n server th√†nh c√¥ng.")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå L·ªói khi g·ª≠i d·ªØ li·ªáu x·ª≠ l√Ω: {e}")

    def stop(self):
        self.running = False
        print("üõë ProcessingWorker ƒë√£ d·ª´ng.")