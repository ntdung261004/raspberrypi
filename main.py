import sys
import cv2
import numpy as np
from datetime import datetime
from threading import Thread
import queue
import time
from typing import Optional, Tuple, List
import base64
import requests
from flask import Flask, jsonify
from collections import deque
import RPi.GPIO as GPIO

from module.camera_module import Camera
from module.detection_module import ObjectDetector
from app import ProcessingWorker 
from utils.audio import play_event_sound

# Thay th·∫ø b·∫±ng ƒë·ªãa ch·ªâ IP ch√≠nh x√°c c·ªßa m√°y Mac c·ªßa b·∫°n
SERVER_MAC_URL = "http://192.168.1.196:5000"

# --- C·∫•u h√¨nh GPIO cho n√∫t b·∫•m ---
GPIO.setmode(GPIO.BCM)
TRIGGER_PIN = 17
GPIO.setup(TRIGGER_PIN, GPIO.IN, pull_up_down=GPIO.PUD_DOWN) 

# B·ªô ƒë·ªám v√≤ng ƒë·ªÉ l∆∞u tr·ªØ c√°c khung h√¨nh g·∫ßn nh·∫•t
RING_BUFFER = deque(maxlen=2)

class SenderWorker(Thread):
    def __init__(self, frame_queue):
        super().__init__()
        self.frame_queue = frame_queue
        self.daemon = True
        self.running = True

    def run(self):
        while self.running:
            try:
                jpg_buffer = self.frame_queue.get(timeout=0.1)
                try:
                    requests.post(
                        f"{SERVER_MAC_URL}/video_upload",
                        data=jpg_buffer,
                        headers={'Content-Type': 'image/jpeg'},
                        timeout=0.5
                    )
                except requests.exceptions.RequestException:
                    pass
                self.frame_queue.task_done()
            except queue.Empty:
                continue

    def stop(self):
        self.running = False

def set_zoom(picam2, zoom_factor, stream_size):
    """
    Thi·∫øt l·∫≠p zoom k·ªπ thu·∫≠t s·ªë, ƒë·∫£m b·∫£o gi·ªØ ƒë√∫ng t·ª∑ l·ªá khung h√¨nh c·ªßa stream.
    zoom_factor: 1.0 = kh√¥ng zoom, 2.0 = zoom 2x.
    stream_size: Tuple (width, height) c·ªßa khung h√¨nh cu·ªëi c√πng (v√≠ d·ª•: (480, 640)).
    """
    if zoom_factor < 1.0:
        zoom_factor = 1.0

    full_width, full_height = picam2.camera_properties['PixelArraySize']
    stream_width, stream_height = stream_size

    # T√≠nh t·ª∑ l·ªá khung h√¨nh c·ªßa stream (v√≠ d·ª•: 480/640 = 0.75)
    target_aspect_ratio = stream_width / stream_height

    # T√≠nh to√°n k√≠ch th∆∞·ªõc v√πng crop ban ƒë·∫ßu
    crop_width = full_width / zoom_factor
    crop_height = full_height / zoom_factor

    # ƒêi·ªÅu ch·ªânh v√πng crop ƒë·ªÉ c√≥ t·ª∑ l·ªá khung h√¨nh ch√≠nh x√°c
    # B·∫±ng c√°ch gi·ªØ chi·ªÅu cao v√† t√≠nh l·∫°i chi·ªÅu r·ªông
    new_crop_width = crop_height * target_aspect_ratio
    
    # N·∫øu chi·ªÅu r·ªông m·ªõi nh·ªè h∆°n chi·ªÅu r·ªông crop ban ƒë·∫ßu, ta d√πng n√≥.
    # Ng∆∞·ª£c l·∫°i, ta ph·∫£i gi·ªØ chi·ªÅu r·ªông v√† t√≠nh l·∫°i chi·ªÅu cao.
    if new_crop_width <= crop_width:
        crop_width = new_crop_width
    else:
        crop_height = crop_width / target_aspect_ratio

    # T√≠nh to√°n ƒëi·ªÉm b·∫Øt ƒë·∫ßu ƒë·ªÉ crop t·ª´ ch√≠nh gi·ªØa c·∫£m bi·∫øn
    crop_x = (full_width - crop_width) / 2
    crop_y = (full_height - crop_height) / 2
    
    # T·∫°o v√† √°p d·ª•ng v√πng crop
    crop_region = (int(crop_x), int(crop_y), int(crop_width), int(crop_height))
    picam2.set_controls({"ScalerCrop": crop_region})
    print(f"üîé ƒê√£ thi·∫øt l·∫≠p zoom k·ªπ thu·∫≠t s·ªë: {zoom_factor}x, gi·ªØ t·ª∑ l·ªá {stream_width}:{stream_height}")

def run_main():
    stream_width, stream_height = 480, 640
    cam = Camera(width=stream_width, height=stream_height)
    
    processing_queue = queue.Queue(maxsize=5)
    frame_queue = queue.Queue(maxsize=10)
    detector = ObjectDetector(model_path="my_model.pt")
    
    cam.start()
    
    # √Åp d·ª•ng zoom 3x, b·∫°n c√≥ th·ªÉ thay ƒë·ªïi s·ªë n√†y
    set_zoom(cam.picam2, 5, (stream_width, stream_height))
    print("üî• ƒêang kh·ªüi ƒë·ªông v√† l√†m n√≥ng h·ªá th·ªëng... Vui l√≤ng ch·ªù.")
    dummy_frame = cam.capture_frame()
    if dummy_frame is not None:
        detector.detect(dummy_frame)
    print("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
    
    processing_worker = ProcessingWorker(process_queue=processing_queue, detector=detector)
    processing_worker.start()
    sender_worker = SenderWorker(frame_queue)
    sender_worker.start()
    
    time.sleep(2)
    play_event_sound(-1) # Ph√°t √¢m thanh kh·ªüi ƒë·ªông
    print("üé• Camera ƒë√£ kh·ªüi ƒë·ªông th√†nh c√¥ng. B·∫Øt ƒë·∫ßu livestream...")
    
    previous_button_state = GPIO.LOW
    
    try:
        while True:
            # Ch·ª•p khung h√¨nh m·ªõi nh·∫•t li√™n t·ª•c v√† ƒë∆∞a v√†o b·ªô ƒë·ªám v√≤ng
            frame = cam.capture_frame()
            if frame is None:
                continue
            RING_BUFFER.append(frame)

            h, w, _ = frame.shape
            center_x, center_y = w // 2, h // 2
            cv2.drawMarker(frame, (center_x, center_y), (0, 0, 255), 
                           markerType=cv2.MARKER_CROSS, markerSize=30, thickness=2, line_type=cv2.LINE_AA)

            _, jpg_buffer = cv2.imencode('.jpg', frame, [int(cv2.IMWRITE_JPEG_QUALITY), 75])
            
            if frame_queue.qsize() < frame_queue.maxsize:
                frame_queue.put(jpg_buffer.tobytes())
            
            current_button_state = GPIO.input(TRIGGER_PIN)
            
            if current_button_state == GPIO.HIGH and previous_button_state == GPIO.LOW:
                
                play_event_sound(-3) # Ph√°t √¢m thanh "ƒê√£ b·∫Øn"

                if len(RING_BUFFER) > 0:
                    frame_to_process = RING_BUFFER[-1]
                    if processing_queue.qsize() < processing_queue.maxsize:
                        processing_queue.put((frame_to_process.copy(), capture_time))
                    else:
                        print("‚ö†Ô∏è H√†ng ƒë·ª£i x·ª≠ l√Ω ƒëang ƒë·∫ßy, b·ªè qua frame.")
                else:
                    print("‚ö†Ô∏è B·ªô ƒë·ªám v√≤ng r·ªóng, kh√¥ng c√≥ khung h√¨nh ƒë·ªÉ x·ª≠ l√Ω.")

            previous_button_state = current_button_state
            time.sleep(0.01)
                
    except KeyboardInterrupt:
        print("\nüõë L·ªói h·ªá th·ªëng, tho√°t...")
    finally:
        processing_worker.stop()
        sender_worker.stop()
        cam.stop()
        cv2.destroyAllWindows()
        GPIO.cleanup()


if __name__ == '__main__':
    run_main()